<!DOCTYPE html>

<head>
  <title> CART 263 WINTER 2026</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100..900;1,100..900&display=swap"
    rel="stylesheet">

  <link rel="stylesheet" href="css/style.css">
  <link href="css/themes/prism.css" rel="stylesheet" />


</head>

<body>
  <header>
    <h1> CART 263 WINTER 2026</h1>

    <nav id="cart263Nav"></nav>
    <script src="js/loadNav.js"></script>
    <div class="inner-head">
      <h1> MEDIA APIs</h1>
    </div>
  </header>
  <main>

    <section class="contents-notes">
      <h3> The Media Capture API I</h3>
      <p>This lesson will demonstrate how to use the the <a
          href="https://developer.mozilla.org/en-US/docs/Web/API/Media_Streams_API">Media Capture API</a> in order to be
        able to capture live streaming video and audio media.</p>
      <h4> Capture Live Video I </h4>
      <p>The <code>getUserMedia API</code> provides access to multimedia streams (video, audio, or both) from local
        devices. Previously, we needed a 3rd party plugin - now HTML 5 has support. You need to use this API to access
        the camera, microphone etc... </p>
      <p>The <code>getUserMedia API</code> exposes just one method called <code>getUserMedia()</code>.</p>
      <p>The first example, seen below demonstrates how to setup the basic code template for capturing video from the
        users web cam, storing it, and displaying it using the <span class="customP">html5 video</span> element:</p>
      <pre id="writeA" class="language-html line-numbers">
<script>
  let s = ""
  for (let i = 1; i < 47; i++) {
    if (i % 2 === 0) {
      s += `${i},`
    }
  }
  document.querySelector("#writeA").setAttribute("data-line", s)
</script>
<code>
&lt;!DOCTYPE html&gt;
  &lt;head&gt;
    &lt;meta charset="UTF-8"&gt;
    &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"/&gt;
    &lt;title&gt;getUserMedia Demo&lt;/title&gt;

    &lt;link rel="preconnect" href="https://fonts.gstatic.com" /&gt;
    &lt;link href="https://fonts.googleapis.com/css2?family=Roboto&display=swap" rel="stylesheet" /&gt;

    &lt;style&gt;
        body {
            background: rgb(52, 52, 52);
            margin: 0;
            padding: 0;
            color: rgb(42, 38, 38);
            opacity: .85;
            font-family: 'Roboto', sans-serif;
            width: 100vw;
        }

        h1 {
            text-align: center;
            color: rgb(226, 43, 141);

        }
    main{
      width:50%;
      margin:0 auto;
      background:grey;
    }
      #video
      {
        display: block;
      }
      .mirror {
    /* Mirror the video horizontally */
    -webkit-transform: scaleX(-1); /* Safari and Chrome */
    transform: scaleX(-1);
}
 &lt;/style&gt;
 &lt;script type="text/javascript" src="js/getUserMedia.js"&gt;&lt;/script&gt;
 
  &lt;/head&gt;
  &lt;body&gt;
 
    &lt;h1&gt;Access Camera Example&lt;/h1&gt;
    &lt;main&gt;
    &lt;video class = "mirror" id="video" autoplay="autoplay" controls="true"&gt;&lt;/video&gt;
  &lt;/main&gt;
&lt;/body&gt;
&lt;/html&gt;
</code>
</pre>
      <p>The HTML page sets up the necessary video element - without a source.
        Why? Because we will set up the source using javascript:<code> js/getUserMedia.js: </code></p>
      <pre data-line="1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45"
        class="language-javascript line-numbers">
<code>
window.onload = getLiveVideo;

async function getLiveVideo() {
  console.log("loaded");
  let video = document.getElementById("video");
  console.log(video.srcObject);

  try {
    let stream = await navigator.mediaDevices.getUserMedia({
      video: {},
    });
    video.srcObject = stream;
    console.log(video.srcObject) //here there is something
  } catch (err) {
    /* handle the error */
    console.log("had an error getting the camera");
  }
}
</code>
</pre>
      <p>The <a href="https://developer.mozilla.org/en-US/docs/Web/API/Navigator">navigator object (part of the  Navigator API)</a> 
        contains information about the browser- and exposes properties and methods that one can program against.</p>
      <p>The <code>MediaDevices.getUserMedia()</code> method prompts the user for permission to <span class = "customP">use a media input</span> which
        produces a <code>MediaStream</code> with tracks containing the requested types of media.
        <br />That stream can include a video track (produced by video source such as a camera), and/or an audio track
        (produced by a physical or virtual audio source like a microphone).
      </p>
      <p>The <code>MediaDevices.getUserMedia()</code>returns a <a
          href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise">Promise</a>
        which resolves to this MediaStream object.</p>
      <p>If the user denies permission, or matching media is not available, then the <code>promise</code> is rejected with
        <code>NotAllowedError</code> or <code>NotFoundError</code> respectively.
        <br/>Upon success we then assign the resolved <code>Mediastream object</code> to the <code>srcObject</code> of the HTML video
          element.
        <br />Instead of feeding the video the <code>URL of a media file</code>, its being fed a <code>MediaStream</code> from the webcam.
        <br />Note: we also set the <code>video</code> to autoplay, otherwise it would be frozen on the first frame and
        we would need to specify it to play within the code.
        <br /><br /><strong>Please Note: it is beyond the scope of this class to delve into javascript
          <code>Promises</code></strong>.
        <br />Just think of it here as a mechanism to <em> wait </em> for the user to give permission or for the
        video source to be available before the code continues to execute.
      </p>
      <h4> Capture Live Video II </h4>
      <p>The <code>getUserMedia()</code> allows for one to specify if one also requires <code>audio</code> as well as properties like <code>size</code>.
        <br />Lets alter the function call to include parameters for <code>width and height</code>.
      </p>
      <pre data-line="1,3,5,7,9,11,13" class="language-javascript line-numbers">
<code>
let stream = await navigator.mediaDevices.getUserMedia({
      video: {
        width: 320,
        height: 240,
      },
    });
</code>
</pre>
      <h4> Capture Live Video III and the Canvas </h4>
      <p>We can now show <code>live video</code> displayed using the HTML video element.
        <br />But we can do even better -- we can <strong>also use the HTML 5 <code>canvas</code> to display every frame of
          video and then we can also <code>manipulate/change/adapt</code> the video pixels!</strong></span>
        <br />We will still use the video element as the container to hold the streaming content - but then we will
        display the video content using the canvas context.
        <br>The new HTML markup:
      </p>
      <pre data-line="1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49"
        class="language-html line-numbers">
<code>
&lt;!DOCTYPE html&gt;
&lt;head&gt;
  &lt;meta charset="UTF-8"&gt;
  &lt;meta name="viewport" content="width=device-width, initial-scale=1.0" /&gt;
  &lt;title&gt;getUserMedia Demo II&lt;/title&gt;


  &lt;link rel="preconnect" href="https://fonts.gstatic.com" /&gt;
  &lt;link href="https://fonts.googleapis.com/css2?family=Roboto&display=swap" rel="stylesheet" /&gt;

  &lt;style&gt;
    body {
      background: rgb(52, 52, 52);
      margin: 0;
      padding: 0;
      color: rgb(42, 38, 38);
      opacity: .85;
      font-family: 'Roboto', sans-serif;
      width: 100vw;
    }

    h1 {
      text-align: center;
      color: rgb(226, 43, 141);

    }

    main {
      width: 50%;
      margin: 0 auto;
      background: grey;
    }

    #video {
      display: block;
    }

  &lt;/style&gt;
  &lt;script type="text/javascript" src="js/getUserMediaAndCanvas.js"&gt;&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;

  &lt;h1&gt;Access Camera and Show on Canvas&lt;/h1&gt;
  &lt;main&gt;
    &lt;video id="video" autoplay="autoplay" controls="true"&gt;&lt;/video&gt;
    &lt;canvas id="videoCanvas" width=640 height=240&gt;&lt;/canvas&gt;
  &lt;/main&gt;
&lt;/body&gt;
&lt;/html&gt;
</code>
</pre>
      <p>First we set up the <code>html 5 canvas and context</code>, set up an <code>animation loop</code> and within that use the
      context's <code>drawImage()</code>method to display the next video frame:
      <pre data-line="1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39" class="language-javascript line-numbers">
<code>
window.onload = getLiveVideo;

async function getLiveVideo() {
  console.log("loaded");
  let video = document.getElementById("video");
  let canvas = document.getElementById("videoCanvas");
  let context = canvas.getContext("2d");

  try {
    let stream = await navigator.mediaDevices.getUserMedia({
      video: {
        width: 320,
        height: 240,
      },
    });
    video.srcObject = stream;
    console.log(video.srcObject); //here there is something
    /*** instead of using the video object we can use the canvas **/
    requestAnimationFrame(run);
    function run() {
      context.clearRect(0, 0, canvas.width, canvas.height);
      context.save();
      context.clearRect(0, 0, canvas.width, canvas.height);
      //put onto canvas
      //translate to center and scale on x axis - flip ..
      context.translate(canvas.width/2, 0) 
      context.scale(-1, 1)
      context.drawImage(video, 0, 0, canvas.width / 2, canvas.height);
      context.restore()
      context.fillStyle = "#FFFFFF";
      context.fillRect(10, canvas.height / 2, 50, 50);
      requestAnimationFrame(run);
    }
  } catch (err) {
    /* handle the error */
    console.log("had an error getting the camera");
  }
}
</code>
</pre>
      <p>If you run the page - you should now see the video displaying in the canvas ..
        <br>Also note - how we can <code>flip</code> the video image (mirror): very similar to how you would resolve this issue in p5 ;)
        <br />Let's now go one step further and use some <code>inbuilt methods to
            access the pixels in the canvas</code> and modify them.
        <br />The new <code>run()</code> will now be <code>run_pixels()</code>:
      </p>
      <pre data-line="1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39" class="language-javascript line-numbers">
<code>
  requestAnimationFrame(run_pixels);
    function run_pixels() {
      context.save();
      context.clearRect(0, 0, canvas.width, canvas.height);
      // translate to center and scale on x axis - flip ..
      context.translate(canvas.width / 2, 0);
      context.scale(-1, 1);
      //put onto canvas
      context.drawImage(video, 0, 0, canvas.width / 2, canvas.height);
      context.fillStyle = "#FFFFFF";
      let frame = context.getImageData(0, 0, canvas.width / 2, canvas.height);
      // every pixel has an r,g,b,a value ... and so in the array - every 4 values== 1 pixel
      for (let i = 0; i < frame.data.length; i += 4) {
        let r = frame.data[i];
        let g = frame.data[i + 1];
        let b = frame.data[i + 2];
        let a = frame.data[i + 3];
        frame.data[i] = r;
        frame.data[i + 1] = 0;
        frame.data[i + 2] = 0;
        // make every 8th pixel have an alpha of 0/
        if (i % 32 == 0) {
          frame.data[i + 3] = 0;
        }

        if (i % 8 === 0) {
          frame.data[i + 2] = 255;
        }
      }
      context.putImageData(frame, 0, 0);
      context.restore();
      //can draw on top ...
      context.fillRect(0, canvas.height / 2, 50, 50);

      requestAnimationFrame(run_pixels);
    }
</code>
</pre>
      <p>Two new functions have been introduced here: <code>the getImageData()</code> returns an <span
          class="customP">ImageData object</span>.
        <br />The ImageData object represents the underlying pixel data of an area of a canvas object. It contains the
        following read-only attributes:
      </p>
      <ul>
        <li>width:: The width of the image in pixels.</li>
        <li>height:: The height of the image in pixels.</li>
        <li>data: An integer array representing a one-dimensional array containing the data in the RGBA order,
          with integer values between 0 and 255 (included).</li>
      </ul>
      <p>And we use this function to access the specific pixel data that we want to manipulate.
        <br />Second: the <code>putImageData(img, dx,dy)</code> function is used to paint pixel data into a context.
        <br />The dx and dy parameters indicate the device coordinates within the context that you want to draw into.
      </p>
      <p> Finally - if you do not want to see the original video source you can set the video's <code>display</code> property:
      <pre data-line="1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31" class="language-javascript line-numbers">
        <code>
          video.style.display = "none"
          </code>
          </pre>
        </p>
  </main>
  </section>
  <script src="js/prism.js"></script>
</body>

</html>